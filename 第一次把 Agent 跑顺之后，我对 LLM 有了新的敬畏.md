# 第一次把 Agent 跑顺之后，我对 LLM 有了新的敬畏

最近在 Deeplearning AI 学习 CrewAI 的课程后，感觉这个 agent + workflow 很不错。以前看到的更多是移动模块来链接功能，达到一个自动化。而 CrewAI 呢，是可以有更多自定义的，甚至可以自定义每个 agent 的 temperature，这一点对我这种经常处理数据的人来说，非常有吸引力。

既然学完了课程，我就打算先做个简单的功能吧，毕竟没用过 CrewAI，要先探索一下。

我的目标很简单，我只想做个收集网站里关于 AI 的新闻，并且要给收集到的新闻评分，只选取前五个值得关注的新闻，每周收集一次过去7天的新闻，最后输出并发送到邮箱。我还给自己一个要求，用里面不花钱的 tools 来完成本次目标。先用免费的跑通底层，以后升级功能再用收费工具，这样可以专注在工具搭建的底层逻辑。

本工具一开始最主要的任务是，找新闻来源。我把新闻来源分成了3个部分，第一部分是著名 AI 公司官网，第二部分是有名气的 AI 行业人员的 blog 以及 投资机构官网，第三部分是涉及 AI 板块的科技媒体。新闻来源的重要性排序，我是以研究和产品为主，其他为辅的思路。我主要想关注的是 AI 行业的前沿发展的新闻，所以这里面比较少有“使用心得”以及“使用技巧”的文章来源。

一开始我是用 gpt 帮我找网址，再加上一些博主推荐的博客，大概不到40个网址。这时候我要去一个个网址看内容是否符合，这时候的我还天真的以为要把整个 URL 复制下来，方便 LLM 准确来到网页，减少 token 的使用，殊不知，这时候我给自己悄悄挖了坑。

整理完网址后，来到 CrewAI Studio界面，先让 CrewAI assistant 生成一个模板。不得不说这样可以提升很多效率，一方面是可视化地组织 agent 和 task，另一方面是可以直接生成完整项目结构，方便后续深度修改。当然，我还是选择在 Studio 界面进行修改，我喜欢可视化带来的确定性。

当你高兴的把网址筛选后，把网址分门别类的放进 task，点击运行后。一个未曾想过的问题出现了。

超时了。没想到运行了很久后，系统提示运行超过600s了。

这时候我必须要提一下 CrewAI 里，我最喜欢的功能了，tools 调用记录，这可以非常方便的让你知道是在哪一步出了问题，这样不需要自己去配置跟踪文件了，在 studio 里是默认的。如果是在 python 文件里，你只需要在设置 Crew 函数时，让 verbose = True，默认是 False。

我通过调用记录查看这次运行卡在了第一个 agent，主要负责搜索文章的 agent，而且还只运行了几个网址就卡住了，我觉得很奇怪。当时我猜测有几个原因，一个是 tools 没选好，导致性能比较差；一个是 prompt 没有写好，限制还不够；一个是网址内容可能不适合抓取。我带着疑问逐个排查。

我先是让 assistant 给我换了其他的 tool 进行测试，确实能多抓取几个网址，一度以为问题解决了。但重复测试几次后发现，这种提升并不稳定，最终依旧会超时。

第二步开始优化 prompt，把第一个 agent 的 task 的 description 以及目前发现的问题，加上我的目的发送给 ChatGPT，希望 ChatGPT 能帮我设置好运行边界，处理好内在逻辑。优化了 prompt 以后，确实好多了，这次最高能抓取的网站又多了。可惜的是，重复测试了好几次，依旧超时。

在重复测试了十几次以后，我开始发现了一些规律。每次测试后，我都会去看一下卡在了什么网站，测试多了，我发现有些网站很容易卡住，这让我提高了效率，我只需要检查频繁卡住的网址，一个是看网页是否容易有弹窗，一个是看网页内容的更新频率。检查后我并没有一次性全部删除，我是按顺序打开网页检查一个，删除一个，测试一次，直到全部跑通，我还是想要尽量多抓取一些文章来评分对比。最后我从快40个网址，缩减到了不到20个网址。虽然大幅减少了网址，但现在可以跑通了，至少可以全部流程运行成功了，以后还是可以继续完善网址的。

很不错，非常好，这个 agents 的流程跑通了，可以运行了。新的大挑战来了。

在最后 Editor Agent 输出的结果中，我发现了不属于过去7天的新闻，而且数量超过一半。我的侥幸心理开始作祟，我又测试了一次。结果依旧是存在很多大于7天的新闻。我检查了我的 Source Analyst Agent 及其 task 的 prompt，其实都有“过去七天”的要求。

我尝试使用 CrewAI assistant 的自动修复功能，我开始祈祷。结果有好有坏。好消息是新闻都是过去七天的，坏消息是新闻都不是从给定网址里找的，而是直接简化了搜索，改成“上网搜索过去7天的新闻”。直接把我原有的网址删了，还修改了任务目标。幸好有 restore 功能，我只能另找办法。

第一次尝试是更加详细描述“过去七天”的含义，测试过后发现依旧是有问题的。

第二次尝试是让 tool 在查看网页时，着重查看时间，测试过后发现依旧是有问题的。

第三次尝试是直接让 LLM 进行简单的日期计算。在查看网页的时候会记录下”published_date”以及”published_days_ago”，直接计算出与当前日相比是在几天前。这次测试后，终于成功了，而且测试好几次都没出错。

现在回想起来，“过去 7 天”对于我们人类来说是非常简单的概念，我们会默认它是“从今天起”向前回溯。但对于 LLM 来说，这并不一定是自然存在的大前提。我当时用的是 gpt-4.1，也让我更清楚地意识到：有些我们以为“理所当然”的时间概念，并不会自动成为模型的默认前提。而让 agents 提高效率和效果的方法，往往正是去深挖这些“理所当然”，把潜意识里的假设一点点抬出水面。

这次的项目虽然简单，但是在做项目的时候还是学到了很多东西：

1. 对于给 LLM 边界是非常重要的事情，LLM 知道太多东西，如果不加以极大的限制，是很难完成某个细致专精的任务的。
2. 对于“一键修复”功能还是要保持敬畏之心，也要做好能随时“回溯”的准备。如果在“一键修复”的时候可以添加简单的，限制字数的附言可能会更加好。或者给个保持现在不变的大前提，只修改某一部分的选项。
3. 做点什么。不管简单的，复杂的，还是要弄脏自己手才能有更加切身，更加深刻的感受。
4. 当你面对失败没有灵感的时候，可以站起来走走，回来在和你自己的 LLM 探讨一番。
5. 不要畏惧失败，失败是前进的道路。我也在这过程中，培养了心智，在失败面前更有勇气。

虽然这个项目已经可以正常运行了，但其实还有很多地方可以修改，以下是一些想法：

1. 对于评分架构还可以更加细致化，就像考试中不同题目不同得分。
2. 可以继续增加新闻来源，扩大收集的范围。
3. 可以尝试使用收费的 tools 以及 LLM。
4. 可以改善 Editor Agent 最后输出的格式，使得内容更具有可读性，能抓住读者的好奇心。
5. 可以拆分 Source Analyst Agent 成两个 agent，一个只负责找到符合时间的文章，并记录下 url，另一个只负责抓取文章内容。相当于一个是时间过滤器，另一个是文章记录者。功能拆的越简单，agents 越容易成功，而且后期想要重复利用单个功能也能实现。

继续学习，也继续把手弄脏

Sean Chen